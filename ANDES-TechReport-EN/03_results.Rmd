# Results

## Architecture
The architecture of \gls{andes} differs significantly from that of its predecessor (see Figure \@ref(fig:arch)).
The application and its associated services are centralized on one or several servers and include:
1) a web-service for handling HTTP requests and responses;
2) a database service for storing data associated with the application;
3) a file-sharing service for handling the storage of backups and related files;
4) a printing service used for printing out specimen labels; and
5) a message-brokering service for handling asynchronous tasks.
Client devices, such as data-entry workstations, no longer require the installation of anything more than a modern web browser; i.e., one that is capable of supporting HTML5 and ECMAScript 2016 (Javascript).
Accordingly, this increases the range of devices and operating systems that may be used for accessing the application.
For instance, the switch to using \gls{andes} has allowed for the integration of mobile phones, tablets and linux workstations into the data entry workflow.
Finally, the new configuration means multiple stations can simultaneously receive and enter data into the same \gls{andes} instance.

The [Django Web Framework](https://www.djangoproject.com/) was selected for the backend of this application due to its modularized nature; virtually all aspects of the programming framework can be decoupled.
Furthermore, the Django framework is written in pure Python languageâ€”an open-source, generalized object-oriented programming language that is popular for use in data-heavy applications.
In addition to standard Django templates used to render HTML webpages to end-users, the web framework also contains an elaborate \gls{REST-API} component.
Django uses an \gls{ORM} to handle the data layer, and includes \gls{api}s for a variety of modern relational database management systems (i.e., PostgreSQL, MariaDB, MySQL, Oracle, SQLite, etc.).
Several of the application's frontend templates contain reactive components implemented in \gls{vuejs}.

The frontend of the application is built in \gls{html5}, \gls{javascript} and \gls{CSS}.
Most users will be familiar with the flow and functionality of a web browser and will be comfortable navigating and entering data into a website.
Facilitated by the Django model and form classes, all controls (i.e., fields) on the website contain verbose descriptions and help text.
The [Bootstrap v5.0](https://getbootstrap.com/docs/5.0/getting-started/introduction/) \gls{CSS} and \gls{javascript} libraries were utilized in order to give the application a sleek, modern look and to ensure compatibility with different types of devices (e.g., personal computers, tablets and mobile devices).
The Bootstrap library also provides palatable styles for displaying help text in the form of popups and tool tips.

While web applications are most often used over a network, the Django library comes with a development web-server that permits users to serve and use the application locally.
In this scenario, a single computer acts simultaneously as server and client.
While there are important limitations to the use of the Django development web-server in a full-scale production environment, the option to run and use \gls{andes} on a single device is an advantage for stand-alone, non-networked usage cases (e.g. field tablet used for port sampling).

The architecture used by \gls{andes} creates networking requirements that were not previously present in the \gls{ese} and \gls{mrr} (i.e., under scenarios where they are not the same device).
The server and the client devices must be connected to the same network.
The network does not need to have access to the \gls{wan} (i.e., the internet) connection.
As long as they are connected to the same \gls{lan}, they can be configured to work together.
This suits the networking environment on board remote vessels that can have sporadic connection failures with the outside world.

The \gls{andes} application provides access to its various components based on an internal system of authentication and authorization.
The credentials of a given user will affect what action they are able to do.
For example, while the chief scientist is able to modify sampling requirements for the mission, other users are not.


## Andes Modules

The main index page of the \gls{andes} user interface (Figure \@ref(fig:screenshot-index)) allows users to access several different modules that loosely correspond to the main use cases defined in the above Methods section.
Access to the different modules is determined by a system of authentication and authorization.
Consequently, the index page will appear different to users depending on the permissions they have been granted.

While \gls{andes} has been implemented using a modular design, there is a core set of components that are used across modules.
This is true at the level of the database, where in addition to a number of shared tables, sub-modules will have tables that are specific to a given use case.
For example, while the Mission table is used across several modules, the Specimen table is specific to the Ecosystem Survey module.

Similarly, \gls{andes} has modules that are used across multiple user scenarios; in particular, the Bridge module (Figure \@ref(fig:screenshot-bridge-console)) and the Cruise Dashboard (Figure \@ref(fig:screenshot-dashboard)).
These modules display high-level information to end users such as queued stations, vessel speed, position, heading and various summaries of science activities that are underway or that have already taken place.
All core pages of the application can be toggled to night mode, as desired.

Within the application's configuration settings, modules can be enabled and disabled at both the user-level and the mission-level.
For example, on an ecosystem survey that is also conducting oceanography data collection, the oceanographic technician will have access to the Oceanography app while technician in the wetlab  will not.
On single-purpose missions, modules can be toggled on or off for all users, thereby essentially stripping unneeded components from the user interface.


### Bridge

The Bridge module (Figure \@ref(fig:screenshot-bridge-console)) is used by navigation and fishing officers in the wheelhouse (usually on a tablet) to input fishing set metadata.
The data entry occurs in two ways: 1) by manually editing the set form (a.k.a. the set card); and/or 2) via the Fishing Console, which is displayed in Figure \@ref(fig:screenshot-fishing-console).
The Fishing Console can directly capture a GPS feed to record the time and location of a number of different user-defined events that take place during fishing.
Through the application settings, these events can be configured to trigger downstream actions, such as the starting/ending the capture of data from the sonar and trawl mensuration system sensors (e.g., Scanmar system).
The Bridge console also links directly to the Trawl Validation console which provide realtime feedback and validation of trawl mensuration system sensors \@ref(fig:screenshot-trawl-validation).

### Set Manager

The Set Manager module is used to manage upcoming sets and review completed set cards.
Typically accessed by the chief scientist and team leads, it provides the ability to select upcoming sampling locations and initialize the corresponding set cards.
The Set Manager module is where sets can be activated and deactivated.
Additionally, this module is where any quality assurance flags associated with a set and its catches can be reviewed and accepted.

### Ecosystem Survey

The \gls{Ecosystem Survey} module is the main entry point that technicians will use to input survey data.
A depiction of the main tables involved in the Ecosystem Survey module, and their relationships are displayed in Figure \@ref(fig:erd-ecosystem-survey).
This component of \gls{andes} replicates the capabilities of the \gls{ese} for capturing detailed information on length, weight, ageing material, maturity, etc. about fish and invertebrate specimens.
This module, typically accessed from the wet laboratory of a survey vessel, is used for all entry of data related to measurements and observations of marine organisms.
New catches are first entered into the Active Catches page, as portrayed in Figure \@ref(fig:screenshot-wetlab-active-set).
The Active Catches page accepts user-defined catch codes as a way to input new catches into a set.
If a code is not known by the user, a search feature is available.
Next, baskets and their corresponding weights and statuses (e.g., sampled vs. not sampled) are then entered into the Catch Card page (Figure \@ref(fig:screenshot-wetlab-catch-card)).
Finally, specimens are entered into the Data Entry page (Figure \@ref(fig:screenshot-wetlab-data-entry)).
As the data entry progresses, users are dynamically prompted with observation fields that follow the catch-specific sampling protocol.
An overview of the sampling protocol is displayed on the right-hand side of the Data Entry page.

### Shrimps

The Shrimps module is an extension of the ecosystem survey module focused exclusively on shrimps as it has different workflow requirements (Figure \@ref(fig:screenshot-shrimps)).
This module provides a special case of \gls{andes}\' subsampling functionality, and allows the user to subsample a total catch of shrimp into different species and maturity stages before collecting biological data (cephalothorax length for all species and occasionally weight for *Pandalus borealis*).
Additional mission and protocol-level configurations are needed prior to this module being used.


### Charts

The Charts module (Figure \@ref(fig:screenshot-charts)) leverages the [Bokeh](https://bokeh.pydata.org) Python library to generate data visualization of arbitrary length and weight observation variables that were attributed to specimens.
The module provides an interactive scatter plot of length vs weight as well as a length histogram.
The data can be filtered by species, set and sex (when available).
This visual presentation of the data is meant as a supplemental validation aid in identifying outliers that may have escaped the quality controls.
Should outlier points need further manual inspection/intervention, a direct link to access/edit the specimen data is conveniently made available.

The user is also presented with options to include an empirical growth model together with weight vs length scatter data.
This option, which only applies for "official" length and weight observation types, can be useful for tuning the tolerance band used for quality control (see Quality Control section below).

### Oceanography

This module is used to track and record the deployment of oceanographic instruments such as CTD/Rosette systems, plankton nets and Argo floats (Figure \@ref(fig:screenshot-oceanography-sample)).
Following the conventions established by \gls{elog}, the deployment of a given instrument is referred to as an "event".
A collection of events carried out at a point in time and space is referred to as an "oceanographic sample".
The Oceanography module is a component of the \gls{andes} application that is capable of being deployed independently of the Ecosystem Survey module.

The module's primary purpose is to capture metadata pertaining to oceanographic samples and events.
In the mission configuration, user-defined "actions" can be programmed in associated with each instrument type.
Typical actions collected for CTDs and plankton tows are "deployed", "on bottom", "recovered" and "abort".
When an action button associated with an event is clicked or "fired", the date/time and location of the occurrence is logged.
Oceanographic actions are analogous to the fishing events described above however instead of being logged at the set / sample level, they are logged at the oceanographic event level.

Instrument-specific metadata is also collected.
For CTD/Rosette deployments, details pertaining to what water samples/parameters were collected from what depths can be recorded (Figure \@ref(fig:screenshot-oceanography-event-ctd)).
Certain parameters, such as eDNA and dissolved oxygen, allow additional observations to be captured in supplementary tables.
For plankton tows, details pertaining to sample identification, mesh size, start depth and end depth can be recorded (Figure \@ref(fig:screenshot-oceanography-event-zooptow)).
The simplified \gls{ERD} of the Oceanography module of \gls{andes} is presented in Figure \@ref(fig:erd-oceanography).

Upon completion of a survey, \gls{andes} is designed to provide a series of oceanographic summary reports that summarize aspects of the data collected:

\begin{description}
\item[Mission instrument report]{Provides a summary of the oceanographic equipment used on the survey, including component type, model, serial number, and date of last calibration (for CTD sensors).}
\item[CTD metadata report]{For each fishing set and station where the CTD/Rosette system was deployed, the date, time, position, sounding, and bottle sample IDs are provided.}
\item[Hydrolog report]{For each fishing set and station number, a summary of the CTD/Rosette and ring net deployments are provided, including the event numbers corresponding to each gear deployment, comments entered into \gls{andes} regarding each gear deployment, summary information related to each set and station, including surface temperature, sounding, day of year, and date/time.}
\item[Plankton report]{This report provides a summary of the plankton net deployments conducted in relation to each fishing set and stratum. The wire out and wire angle, as well as flow meter start and end are provided.}
\item[Bottle report]{This report provides a detailed summary of each CTD/Rosette operation (e.g., altimeter height, bottle height and depth, max. CTD depth), the water samples/parameters collected, and also includes the results of the Winkler titrations for dissolved oxygen samples, if entered into the Oceanographic Activity detail page.}
\item[TS report]{This report provides a summary of the surface and bottom temperature and salinity data from each CTD cast in relation to each set, station, and stratum.}
\item[ELOG report]{This report emulates the .log summary report produced by \gls{elog}. This report is required in order to upload the survey data into the Microsoft Access template used by AZMP to load data to BioChem, DFOs national repository for discrete and plankton data.}
\end{description}

These reports facilitate the post-processing of the data, its integration into existing data repositories and its distribution and upload to various open data platforms.


### Forecasting utility modules
There are a number of task-specific modules designed to assist in mission forecasting and planning.
These modules are designed to provide timely information to scientific staff participating in a research cruise, and to also assist the chief scientist and watch leaders in the planning and execution of a mission.

#### Cruise dashboard {.unlisted .unnumbered}
The cruise dashboard module is used to provide an overview of the current status of a mission to all \gls{andes} users (Figure \@ref(fig:screenshot-dashboard)).
It provides a range of real-time statistics that are used for planning purposes, including current status (e.g., fishing, steaming, deploying/retrieving net), the list of upcoming stations, and data from the latest trawl.

#### Forecasting {.unlisted .unnumbered}
The forecasting tool is designed to provide real-time prognostics of survey completion targets based on assumed transit speeds and time spent fishing and processing the trawl catches (Figure \@ref(fig:screenshot-forecast)).
This feature provides a useful tool for the chief scientist to evaluate different sampling objectives and to compare different survey route options.
As the conditions change regularly during a survey, this tool links with the set manager to provide an estimate of the amount of time required to complete planned stations.
This tool can be used for short-term planning (i.e. a day's worth of sampling) or longer-term planning (i.e. a mission's worth of sampling).

#### Progress Map {.unlisted .unnumbered}
Another task-specific utility is the progress map which shows what strata have been completed based on target and minimum number of sets per stratum.
This map provides the chief scientist with a clear visual depiction of what has been accomplished and what remains to be accomplished during the survey.
The number of sets conducted in each stratum is compared to the minimum and target number of sets per stratum to determine the colour that each stratum will appear in the progress map (Figure \@ref(fig:screenshot-progress)).


### Images
The images module is a component of the Andes application designed to streamline image management during surveys.
The module enables images to be captured and stored directly from the application using a smartphone, tablet or webcam.
Doing so allows images to be directly linked to the set, catch, or specimen that they represent, eliminating the need to manually create this link from a filename after data collection is complete.
Images are queued during data collection based on various triggers (user request, rare catch, sampling protocols, etc. ).
The queued images are listed in the app allowing users to capture them on a camera-enabled device which can be separate from the one being used for data entry.


### Port sampling

\gls{andes} was adapted from a previous port sampling module to support activities where technicians obtain length frequency samples from commercial fishing activities.
The port sampling module of \gls{andes} is stand-alone and is typically used independently of other modules.
Similar to the Ecosystem Survey module, sampling protocols can be defined an implemented for specific catches, however in its current state,
the protocols used in the Port Sampling module are less intricate.
Through these protocols, users are able to control collection quotas (e.g., "keep two specimens per bin"), the flow of data entry (e.g., which field should be displayed in the sample form) and the layout of the data entry page (e.g., length bins organized in a vertical or horizontal configuration) (see Figure \@ref(fig:screenshot-port-protocol)).
Typically, production instances of this module are deployed on ruggedized field tablets that are suitable for use in wet environments.

The design of the user interface is simple and intuitive, where each length bin is a large button on the display.
As specimens are tallied, the corresponding buttons on the touchscreen are pushed.
When the collection quota of a given length bin has been met, the color of the button changes from blue to green.
A screenshot of the data entry page is presented in Figure \@ref(fig:screenshot-port-data-entry).
Data export reports which allow the data from the field tablets to be imported into external production / archival databases are also available.
The various tables of the Port Sampling module and how they relate to one another are shown in Figure \@ref(fig:erd-port).



## Technical Implementation of Other Design Goals


### Version control/source control

[Git](https://git-scm.com/) was selected as the \gls{vcs} for this project due to the fact it is widespread in use and open-source.
The remote repository for this project is currently hosted as a private project on the [Gulf Science organizational GitHub account](https://github.com/dfo-gulf-science).
The project is additionally making use of GitHub infrastructure including, pull requests, issue management (e.g., bugs, feature requests and general enhancement requests), security alerts and version releases.
The \gls{andes} [online documentation](https://dfo-gulf-science.github.io/andes/) is served using GitHub Pages.

### Unit testing

For \gls{andes} development, we use a mixture of test-driven development for critical components of the application, and are also continually adding unit tests for more user-specific components.
Using the built-in Python/Django testing framework, this strikes a middle ground between the two approaches described in the above section.
While the goal is not to impose test-driven development for the application, the use of unit tests is highly encouraged, especially to back up the core functionality of the application.

### Backup strategy

The \gls{andes} application has the capability to perform manual and automatic backups.
These backups consist of two parts: the full contents of the database (in \gls{json} format, in raw SQL format, or a standalone SQLite database file) and metadata pertaining to the current version of the application (i.e., the git hash).
The structure of the application models and associated data structure will change over time with development.
Accordingly, in order to re-instantiate a particular data snapshot, it is critical to know the precise software version from which it originated.
This combination of data export and git version number, gives users the perpetual ability to recreate the exact application environment from the time of the snapshot, no matter how much the application has changed in the interim.
In the application, backups are automatically created upon closing sets.
Moreover, users also have the ability to manually trigger a backup at anytime.

The backup strategy for mediafiles (i.e., sample and specimen images) are slightly different.
When images are captured, copies are automatically synced to the server's backup location, which is typically a mounted share folder pointing to a file server with a /gls{raid} configuration.

### Customizable protocols

\gls{andes} provides project leads the ability to create and modify sampling protocols through the user interface.
By doing so, project leads are able to shape the flow and control the behaviour of the application during data entry.
This includes deciding which fields to display in a form (e.g., set cards), importing stations and other geographical features (e.g., sampling strata, \gls{nafo} areas, \gls{mpa}s, etc.) and the quotas and observation fields associated with different catch items.
Examples of catch-specific sampling requirements that can be programmed by project leads can be found in Table \ref{tab:sampling}.

### Quality control

\gls{andes} implements a suite of quality control checks.
All quality control flags that are raised during data entry are appended to a report and require sign off before a set can be closed.

**Sets**

The \gls{andes} provides clear feedback regarding the completeness status of a given set.
Flags are raised if a set's start and/or end coordinates are outside the expected sampling stratum.
Additionally, an alarm is sounded in the bridge console module when deviating from the desired stratum in real-time.
The bridge console also provides personnel with fishing timers and tow distance displays (see Figure \@ref(fig:screenshot-fishing-console)).

\gls{andes} will create a flag when the tow distance as calculated by the cruise track, differs from the tow distance as calculated by a straight line between the start and end coordinates by more than 5%.
\gls{andes} will flag when the start or stop coordinates of a set are not within the expected \gls{nafo} area (if applicable).

**Catches**

There are numerous flags that can be attributed to individual catches.
Flags are generated for catches that do not have any data entry associated with them.
In addition to this, \gls{andes} will flag when the weights entered for baskets are considered suspect.
This is determined by either the default maximum basket weight (mission level), or the maximum basket weight for a given species.
\gls{andes} will also flag when the difference of total weight of *sampled* basket differs by more than 25% from the total calculated specimen weight.
The total calculated specimen weight is a combination of actual weights (when collected) and those which were estimated from length measurements.
The latter is achieved by using regression coefficients estimated from historical length ($L$ in centimeters) and weight ($W$ in grams) observations using the model,
\begin{equation}
W = aL^{b}
(\#eq:growth-model)
\end{equation}
where $a$ and $b$ are the regression coefficients for a given species.
\gls{andes} offers the option to specify separate regression coefficients for males, females or unspecified individuals (as shown in Figure \@ref(fig:screenshot-ab-form)).

An additional optional layer of quality control allows project leads to assign allow-lists and restrict-lists, commonly known as "whitelists" and "blacklists", to a mission or to a specific geographic feature (e.g., a stratum).
In this way, the validity of each catch entered into a set can be assessed.
For example, if a catch being recorded is *not* on the that set's associated allow-lists, the end user will be notified that this is an unusual observation and will be prompted to collect documentation.
Similarly, if a project lead adds a catch to the mission's restrict-list, users who enter this catch will receive a warning message, asking them to double-check the assignment.
This is useful when project leads want to limit the usage of certain taxa during data entry, e.g., *Alosa* sp. is preferred over the use of *Alosa pseudoharengus*.

**Specimens**

Specimen lengths and length-to-weight ratios are validated against the parameters entered into the sampling requirements for that catch.
Acceptable length-to-weight ratios are assessed by comparing the actual weight to the estimated weight, as described by Equation \@ref(eq:growth-model) in the section above.
Additionally, \gls{andes} will flag when there is a mismatch between fish maturity and somatic length.
Project leads can specify mature length thresholds for males, females or unspecified individuals in the sampling requirement of a given species (as shown in Figure \@ref(fig:screenshot-mature-length-form)).

**Observations**

When entering observations, \gls{andes} enforces the data type of the corresponding observation type; invalid entries are not accepted.
When entering an observation for a categorical observation type, \gls{andes} will display the list of options to the end user and inhibit users from entering invalid selections.
\gls{andes} will also ensure observation types are not left blank.
However, NaN entries are permitted when a particular observation is meant to be skipped.
Certain observation types are meant to be unique, e.g., unique tag number.
If this is flagged at the level of the observation type, end users will be notified if there is a violation of this structure.

### Reactivity

The [Django REST framework](https://www.django-rest-framework.org/) was used to construct the \gls{REST-API} component of the application.
The project takes a hybrid approach, combining the use of standard Django views and \gls{vuejs} frontend applications embedded in the templates.
The latter, which offloads some code execution directly on client devices, was used to avoid the need for constantly reloading webpages and to optimize the flow of traffic across the network.
Reactive javascript frontend applications also provide a better experience from the point of view of an end-user.

### Multilingualism

The Django framework has excellent support for internationalization and localization, including the translation of text and the formatting of dates, times and numbers.
It achieves this using a system of 'hooks' used by developers to indicate which parts of the code should be localized.
See [Django - Internationalization and localization](https://docs.djangoproject.com/en/4.1/topics/i18n/) for more details on this process.
In our application, an end-user can toggle between English and French by simply clicking on a button.
In this way, each client can view the application in the language of their choice.
